{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-21T19:05:39.532175Z",
     "start_time": "2024-10-21T19:05:39.527486Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.constants import year"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:05:39.998646Z",
     "start_time": "2024-10-21T19:05:39.962949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EyeDetector:\n",
    "    def __init__(self, ear_thresh=0.24, max_count=30):\n",
    "        self.index_left_eye = [33, 160, 158, 133, 153, 144]\n",
    "        self.index_right_eye = [362, 385, 387, 263, 373, 380]\n",
    "        self.ear_thresh = ear_thresh\n",
    "        self.count = 0\n",
    "        self.max_count = max_count\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.openEye=None\n",
    "\n",
    "    def __eye_aspect_ratio(self, coordinates):\n",
    "        d_A = np.linalg.norm(np.array(coordinates[1]) - np.array(coordinates[5]))\n",
    "        d_B = np.linalg.norm(np.array(coordinates[2]) - np.array(coordinates[4]))\n",
    "        d_C = np.linalg.norm(np.array(coordinates[0]) - np.array(coordinates[3]))\n",
    "        return (d_A + d_B) / (2 * d_C)\n",
    "    \n",
    "    # this method loop\n",
    "    def detect(self, frame, face_mesh):\n",
    "        height, width, _ = frame.shape\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "\n",
    "        coordinates_left_eye = []\n",
    "        coordinates_right_eye = []\n",
    "        \n",
    "        if results.multi_face_landmarks is not None:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                for index in self.index_left_eye:\n",
    "                    x = int(face_landmarks.landmark[index].x * width)\n",
    "                    y = int(face_landmarks.landmark[index].y * height)\n",
    "                    coordinates_left_eye.append([x, y])\n",
    "                    cv2.circle(frame, (x, y), 2, (0, 255, 255), 1)\n",
    "                    cv2.circle(frame, (x, y), 1, (128, 0, 250), 1)\n",
    "                for index in self.index_right_eye:\n",
    "                    x = int(face_landmarks.landmark[index].x * width)\n",
    "                    y = int(face_landmarks.landmark[index].y * height)\n",
    "                    coordinates_right_eye.append([x, y])\n",
    "                    cv2.circle(frame, (x, y), 2, (128, 0, 250), 1)\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 255), 1)\n",
    "\n",
    "            ear_left_eye = self.__eye_aspect_ratio(coordinates_left_eye)\n",
    "            ear_right_eye = self.__eye_aspect_ratio(coordinates_right_eye)\n",
    "            ear = (ear_left_eye + ear_right_eye) / 2\n",
    "\n",
    "            if ear > self.ear_thresh and self.count <= self.max_count:\n",
    "                self.count += 1\n",
    "                self.openEye = True\n",
    "            elif ear < self.ear_thresh and self.count >= -self.max_count:\n",
    "                self.count -= 1\n",
    "                self.openEye = False\n",
    "        return frame\n",
    "    \n",
    "    # true if 'despierto' else false\n",
    "    def isAwake(self):\n",
    "        return self.count>0\n",
    "    \n",
    "    # true if open eye else false\n",
    "    def isOpenEye(self):\n",
    "        return self.openEye\n",
    "\n",
    "\n",
    "    def get_info(self):\n",
    "        status = \"Despierto\" if self.isAwake() else \"Dormido\"\n",
    "        open = \"Sí\" if self.isOpenEye() else \"No\"\n",
    "        return f\"EYE=>Estado: {status}, Ojos Abiertos: {open}, Contador: {self.count}\"\n",
    "\n",
    "class MotionDetector:\n",
    "    def __init__(self, area_x=100, area_y=100, area_w=200, area_h=200, min_contour_area=5000, max_count=30):\n",
    "        self.area_x = area_x\n",
    "        self.area_y = area_y\n",
    "        self.area_w = area_w\n",
    "        self.area_h = area_h\n",
    "        self.min_contour_area = min_contour_area\n",
    "        self.count = 0\n",
    "        self.max_count = max_count\n",
    "        self.is_move = False\n",
    "\n",
    "    def __intersect_rect(self, x1, y1, w1, h1, x2, y2, w2, h2):\n",
    "        return not (x1 + w1 < x2 or x2 + w2 < x1 or y1 + h1 < y2 or y2 + h2 < y1)\n",
    "\n",
    "    def __is_contained(self, x, y, w, h):\n",
    "        return (x >= self.area_x and y >= self.area_y and x + w <= \n",
    "                self.area_x + self.area_w and y + h <= self.area_y + self.area_h)\n",
    "    \n",
    "    def updatePosition(self, pos_x, pos_y, area_w, area_h):\n",
    "        self.area_x = pos_x\n",
    "        self.area_y = pos_y\n",
    "        self.area_w = area_w\n",
    "        self.area_h = area_h\n",
    "\n",
    "    def detect(self, frame1, frame2):\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        cv2.rectangle(frame1, (self.area_x, self.area_y),\n",
    "                      (self.area_x + self.area_w, self.area_y + self.area_h),\n",
    "                      (0, 0, 255), 2)\n",
    "\n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) < self.min_contour_area:\n",
    "                continue\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            if self.__intersect_rect(x, y, w, h, self.area_x, self.area_y, self.area_w, self.area_h):\n",
    "                cv2.rectangle(frame1, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                self.is_move = True\n",
    "                if self.count <= self.max_count:\n",
    "                    self.count += 1.5\n",
    "\n",
    "        if not self.is_move and self.count >= -self.max_count:\n",
    "            self.count -= 1\n",
    "        if self.is_move:\n",
    "            self.is_move = False\n",
    "        return frame1\n",
    "    \n",
    "    def isAwake(self):\n",
    "        return self.count>0\n",
    "    \n",
    "    #DEPRECATED NOT VALID\n",
    "    def isMove(self):\n",
    "        return self.is_move\n",
    "\n",
    "    def get_info(self):\n",
    "        status = \"Despierto\" if self.isAwake() else \"Dormido\"\n",
    "        move = \"Sí\" if self.isMove() else \"No\"\n",
    "        return f\"MOTION=>Estado: {status}, Movimiento: {move}, Contador: {self.count}\"\n"
   ],
   "id": "798c6d0687598681",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T19:05:46.145418Z",
     "start_time": "2024-10-21T19:05:42.375444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./models/haarcascade_frontalface_default.xml')\n",
    "eye_detector = EyeDetector(ear_thresh=0.24, max_count=30)\n",
    "motion_detector = MotionDetector()\n",
    "\n",
    "with eye_detector.mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=False,\n",
    "        max_num_faces=1) as face_mesh:\n",
    "    while True:\n",
    "        ret, frame1 = cap.read()\n",
    "        ret, frame2 = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        #frame1 = cv2.flip(frame1, 1)\n",
    "        face_rects = face_cascade.detectMultiScale(frame1, scaleFactor=1.3,minNeighbors=3)\n",
    "        if len(face_rects) > 0:\n",
    "            x, y, w, h = face_rects[0]\n",
    "            motion_detector.updatePosition(x, y, w, h)\n",
    "        else:\n",
    "            x, y, w, h = 0,0,0,0\n",
    "            motion_detector.updatePosition(x, y, w, h)\n",
    "            \n",
    "        frame1 = eye_detector.detect(frame1, face_mesh)\n",
    "        frame1 = motion_detector.detect(frame1, frame2)\n",
    "        #print(eye_detector.get_info()) #This method detect if sleep\n",
    "        #print(motion_detector.get_info())\n",
    "        \n",
    "\n",
    "        cv2.imshow('frame', frame1)\n",
    "        key = cv2.waitKey(20) & 0xFF\n",
    "        if key == 27:  # Tecla ESC para salir\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "ab2388c63bd872da",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open zink: /usr/lib/dri/zink_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open zink: /usr/lib/dri/zink_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open zink: /usr/lib/dri/zink_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "W0000 00:00:1729537542.601706   35840 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1729537542.614979   35840 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "46fd1e42ed465b4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
